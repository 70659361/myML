{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import tarfile\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import tensorflow as tf\r\n",
    "#tf.disable_v2_behavior()\r\n",
    "from PIL import Image\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "cach_dir=\"C:/Users/mic/.keras/datasets\"\r\n",
    "train_url=\"http://download.tensorflow.org/data/iris_training.csv\"\r\n",
    "train_path=tf.keras.utils.get_file(train_url.split('/')[-1], train_url, cach_dir)\r\n",
    "\r\n",
    "iris=pd.read_csv(train_path)\r\n",
    "irisNp = np.array(iris)\r\n",
    "irisTf=tf.convert_to_tensor(irisNp)\r\n",
    "irisTf.shape\r\n",
    "\r\n",
    "gpus=tf.config.experimental.list_physical_devices('gpu')\r\n",
    "gpus"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_x=irisNp[:,0:2]\r\n",
    "train_y=irisNp[:,4]\r\n",
    "train_x=train_x[train_y < 2]\r\n",
    "train_y=train_y[train_y < 2]\r\n",
    "num = len(train_y)\r\n",
    "train_x.shape,train_y.shape,num\r\n",
    "plt.scatter(train_x[:,0],train_x[:,1], c=train_y, cmap='brg' )\r\n",
    "plt.show()\r\n",
    "\r\n",
    "X0=np.ones(num).reshape(-1,1)\r\n",
    "#print(num)\r\n",
    "print(X0.shape)\r\n",
    "X=tf.cast( tf.concat((X0,train_x),axis=1), tf.float32)\r\n",
    "print(X)\r\n",
    "Y=tf.cast( train_y.reshape(-1,1), tf.float32)\r\n",
    "print(Y)\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(78, 1)\n",
      "tf.Tensor(\n",
      "[[1.  5.  2.3]\n",
      " [1.  4.9 3.1]\n",
      " [1.  5.7 3.8]\n",
      " [1.  4.4 3.2]\n",
      " [1.  5.4 3.4]\n",
      " [1.  6.7 3.1]\n",
      " [1.  5.1 3.7]\n",
      " [1.  5.2 2.7]\n",
      " [1.  6.9 3.1]\n",
      " [1.  5.8 4. ]\n",
      " [1.  5.4 3.9]\n",
      " [1.  6.3 3.3]\n",
      " [1.  5.7 4.4]\n",
      " [1.  5.4 3.9]\n",
      " [1.  5.2 3.5]\n",
      " [1.  5.8 2.6]\n",
      " [1.  5.4 3. ]\n",
      " [1.  6.7 3. ]\n",
      " [1.  6.3 2.3]\n",
      " [1.  5.1 2.5]\n",
      " [1.  6.4 3.2]\n",
      " [1.  5.1 3.8]\n",
      " [1.  4.8 3. ]\n",
      " [1.  5.1 3.8]\n",
      " [1.  4.7 3.2]\n",
      " [1.  4.8 3.4]\n",
      " [1.  4.6 3.6]\n",
      " [1.  5.  3.3]\n",
      " [1.  6.6 3. ]\n",
      " [1.  6.1 2.8]\n",
      " [1.  5.  3.2]\n",
      " [1.  7.  3.2]\n",
      " [1.  5.  2. ]\n",
      " [1.  5.6 2.5]\n",
      " [1.  6.2 2.2]\n",
      " [1.  4.4 3. ]\n",
      " [1.  5.  3.4]\n",
      " [1.  4.7 3.2]\n",
      " [1.  6.6 2.9]\n",
      " [1.  5.5 3.5]\n",
      " [1.  4.9 3.1]\n",
      " [1.  5.5 2.4]\n",
      " [1.  5.7 2.9]\n",
      " [1.  6.  2.9]\n",
      " [1.  5.4 3.7]\n",
      " [1.  6.1 2.9]\n",
      " [1.  6.5 2.8]\n",
      " [1.  5.6 2.7]\n",
      " [1.  4.9 3.1]\n",
      " [1.  6.8 2.8]\n",
      " [1.  5.7 2.8]\n",
      " [1.  6.  2.7]\n",
      " [1.  5.  3.5]\n",
      " [1.  6.1 2.8]\n",
      " [1.  5.1 3.5]\n",
      " [1.  4.6 3.1]\n",
      " [1.  4.6 3.4]\n",
      " [1.  4.6 3.2]\n",
      " [1.  5.9 3.2]\n",
      " [1.  5.1 3.8]\n",
      " [1.  4.9 3. ]\n",
      " [1.  4.9 2.4]\n",
      " [1.  4.5 2.3]\n",
      " [1.  5.8 2.7]\n",
      " [1.  5.  3.4]\n",
      " [1.  5.2 3.4]\n",
      " [1.  5.3 3.7]\n",
      " [1.  5.  3.6]\n",
      " [1.  5.6 2.9]\n",
      " [1.  4.8 3.1]\n",
      " [1.  5.7 2.8]\n",
      " [1.  5.  3. ]\n",
      " [1.  5.  3.5]\n",
      " [1.  5.5 2.6]\n",
      " [1.  5.7 3. ]\n",
      " [1.  4.4 2.9]\n",
      " [1.  4.8 3. ]\n",
      " [1.  5.5 2.4]], shape=(78, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]], shape=(78, 1), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ce=[]\r\n",
    "acc=[]\r\n",
    "itr=3000\r\n",
    "learn_rate=0.01\r\n",
    "np.random.seed(62)\r\n",
    "W=tf.Variable(np.random.randn(3,1),dtype=tf.float32)\r\n",
    "\r\n",
    "for i in range(itr+1):\r\n",
    "    with tf.GradientTape() as tape:\r\n",
    "        PRED=1/(1+tf.exp(-tf.matmul(X,W)))\r\n",
    "        LOSS=-tf.reduce_mean(Y*tf.math.log(PRED)+(1-Y)*tf.math.log(1-PRED))\r\n",
    "    accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.where(PRED.numpy()<0.5,0.,1.),Y),tf.float32))\r\n",
    "    ce.append(LOSS)\r\n",
    "    acc.append(accuracy)\r\n",
    "\r\n",
    "    dL_dW=tape.gradient(LOSS,W)\r\n",
    "    W.assign_sub(learn_rate*dL_dW)\r\n",
    "\r\n",
    "    print(\"<%d>:Loss: %f, ACC:%f\" %(i,LOSS,accuracy))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<0>:Loss: 1.840436, ACC:0.538462\n",
      "<1>:Loss: 1.756242, ACC:0.538462\n",
      "<2>:Loss: 1.673725, ACC:0.538462\n",
      "<3>:Loss: 1.593151, ACC:0.538462\n",
      "<4>:Loss: 1.514813, ACC:0.538462\n",
      "<5>:Loss: 1.439027, ACC:0.538462\n",
      "<6>:Loss: 1.366123, ACC:0.538462\n",
      "<7>:Loss: 1.296440, ACC:0.538462\n",
      "<8>:Loss: 1.230307, ACC:0.538462\n",
      "<9>:Loss: 1.168036, ACC:0.538462\n",
      "<10>:Loss: 1.109900, ACC:0.538462\n",
      "<11>:Loss: 1.056115, ACC:0.538462\n",
      "<12>:Loss: 1.006831, ACC:0.538462\n",
      "<13>:Loss: 0.962114, ACC:0.538462\n",
      "<14>:Loss: 0.921944, ACC:0.538462\n",
      "<15>:Loss: 0.886213, ACC:0.538462\n",
      "<16>:Loss: 0.854731, ACC:0.538462\n",
      "<17>:Loss: 0.827245, ACC:0.538462\n",
      "<18>:Loss: 0.803447, ACC:0.538462\n",
      "<19>:Loss: 0.782998, ACC:0.538462\n",
      "<20>:Loss: 0.765544, ACC:0.538462\n",
      "<21>:Loss: 0.750729, ACC:0.538462\n",
      "<22>:Loss: 0.738213, ACC:0.538462\n",
      "<23>:Loss: 0.727677, ACC:0.538462\n",
      "<24>:Loss: 0.718830, ACC:0.538462\n",
      "<25>:Loss: 0.711411, ACC:0.538462\n",
      "<26>:Loss: 0.705192, ACC:0.538462\n",
      "<27>:Loss: 0.699974, ACC:0.538462\n",
      "<28>:Loss: 0.695589, ACC:0.538462\n",
      "<29>:Loss: 0.691892, ACC:0.538462\n",
      "<30>:Loss: 0.688761, ACC:0.538462\n",
      "<31>:Loss: 0.686097, ACC:0.538462\n",
      "<32>:Loss: 0.683815, ACC:0.538462\n",
      "<33>:Loss: 0.681844, ACC:0.538462\n",
      "<34>:Loss: 0.680129, ACC:0.538462\n",
      "<35>:Loss: 0.678622, ACC:0.538462\n",
      "<36>:Loss: 0.677285, ACC:0.538462\n",
      "<37>:Loss: 0.676085, ACC:0.538462\n",
      "<38>:Loss: 0.674997, ACC:0.538462\n",
      "<39>:Loss: 0.674001, ACC:0.538462\n",
      "<40>:Loss: 0.673079, ACC:0.538462\n",
      "<41>:Loss: 0.672218, ACC:0.538462\n",
      "<42>:Loss: 0.671405, ACC:0.538462\n",
      "<43>:Loss: 0.670633, ACC:0.538462\n",
      "<44>:Loss: 0.669893, ACC:0.538462\n",
      "<45>:Loss: 0.669179, ACC:0.538462\n",
      "<46>:Loss: 0.668488, ACC:0.538462\n",
      "<47>:Loss: 0.667814, ACC:0.538462\n",
      "<48>:Loss: 0.667154, ACC:0.538462\n",
      "<49>:Loss: 0.666506, ACC:0.551282\n",
      "<50>:Loss: 0.665869, ACC:0.564103\n",
      "<51>:Loss: 0.665239, ACC:0.576923\n",
      "<52>:Loss: 0.664616, ACC:0.576923\n",
      "<53>:Loss: 0.663999, ACC:0.576923\n",
      "<54>:Loss: 0.663386, ACC:0.576923\n",
      "<55>:Loss: 0.662777, ACC:0.576923\n",
      "<56>:Loss: 0.662172, ACC:0.576923\n",
      "<57>:Loss: 0.661570, ACC:0.589744\n",
      "<58>:Loss: 0.660970, ACC:0.615385\n",
      "<59>:Loss: 0.660373, ACC:0.615385\n",
      "<60>:Loss: 0.659777, ACC:0.615385\n",
      "<61>:Loss: 0.659184, ACC:0.641026\n",
      "<62>:Loss: 0.658592, ACC:0.653846\n",
      "<63>:Loss: 0.658001, ACC:0.679487\n",
      "<64>:Loss: 0.657412, ACC:0.692308\n",
      "<65>:Loss: 0.656824, ACC:0.692308\n",
      "<66>:Loss: 0.656237, ACC:0.692308\n",
      "<67>:Loss: 0.655652, ACC:0.705128\n",
      "<68>:Loss: 0.655067, ACC:0.717949\n",
      "<69>:Loss: 0.654484, ACC:0.756410\n",
      "<70>:Loss: 0.653901, ACC:0.769231\n",
      "<71>:Loss: 0.653320, ACC:0.769231\n",
      "<72>:Loss: 0.652739, ACC:0.794872\n",
      "<73>:Loss: 0.652160, ACC:0.794872\n",
      "<74>:Loss: 0.651581, ACC:0.807692\n",
      "<75>:Loss: 0.651004, ACC:0.807692\n",
      "<76>:Loss: 0.650427, ACC:0.807692\n",
      "<77>:Loss: 0.649852, ACC:0.820513\n",
      "<78>:Loss: 0.649277, ACC:0.833333\n",
      "<79>:Loss: 0.648703, ACC:0.846154\n",
      "<80>:Loss: 0.648130, ACC:0.858974\n",
      "<81>:Loss: 0.647558, ACC:0.858974\n",
      "<82>:Loss: 0.646986, ACC:0.858974\n",
      "<83>:Loss: 0.646416, ACC:0.858974\n",
      "<84>:Loss: 0.645847, ACC:0.871795\n",
      "<85>:Loss: 0.645278, ACC:0.871795\n",
      "<86>:Loss: 0.644711, ACC:0.871795\n",
      "<87>:Loss: 0.644144, ACC:0.871795\n",
      "<88>:Loss: 0.643578, ACC:0.871795\n",
      "<89>:Loss: 0.643013, ACC:0.897436\n",
      "<90>:Loss: 0.642449, ACC:0.897436\n",
      "<91>:Loss: 0.641885, ACC:0.897436\n",
      "<92>:Loss: 0.641323, ACC:0.897436\n",
      "<93>:Loss: 0.640762, ACC:0.897436\n",
      "<94>:Loss: 0.640201, ACC:0.897436\n",
      "<95>:Loss: 0.639641, ACC:0.897436\n",
      "<96>:Loss: 0.639082, ACC:0.884615\n",
      "<97>:Loss: 0.638524, ACC:0.884615\n",
      "<98>:Loss: 0.637967, ACC:0.884615\n",
      "<99>:Loss: 0.637411, ACC:0.884615\n",
      "<100>:Loss: 0.636855, ACC:0.884615\n",
      "<101>:Loss: 0.636300, ACC:0.884615\n",
      "<102>:Loss: 0.635747, ACC:0.884615\n",
      "<103>:Loss: 0.635194, ACC:0.884615\n",
      "<104>:Loss: 0.634642, ACC:0.884615\n",
      "<105>:Loss: 0.634090, ACC:0.884615\n",
      "<106>:Loss: 0.633540, ACC:0.884615\n",
      "<107>:Loss: 0.632991, ACC:0.884615\n",
      "<108>:Loss: 0.632442, ACC:0.897436\n",
      "<109>:Loss: 0.631894, ACC:0.897436\n",
      "<110>:Loss: 0.631347, ACC:0.897436\n",
      "<111>:Loss: 0.630801, ACC:0.897436\n",
      "<112>:Loss: 0.630256, ACC:0.897436\n",
      "<113>:Loss: 0.629711, ACC:0.897436\n",
      "<114>:Loss: 0.629167, ACC:0.897436\n",
      "<115>:Loss: 0.628625, ACC:0.910256\n",
      "<116>:Loss: 0.628083, ACC:0.910256\n",
      "<117>:Loss: 0.627542, ACC:0.910256\n",
      "<118>:Loss: 0.627001, ACC:0.910256\n",
      "<119>:Loss: 0.626462, ACC:0.910256\n",
      "<120>:Loss: 0.625923, ACC:0.910256\n",
      "<121>:Loss: 0.625385, ACC:0.910256\n",
      "<122>:Loss: 0.624849, ACC:0.910256\n",
      "<123>:Loss: 0.624312, ACC:0.910256\n",
      "<124>:Loss: 0.623777, ACC:0.910256\n",
      "<125>:Loss: 0.623243, ACC:0.910256\n",
      "<126>:Loss: 0.622709, ACC:0.910256\n",
      "<127>:Loss: 0.622176, ACC:0.910256\n",
      "<128>:Loss: 0.621644, ACC:0.910256\n",
      "<129>:Loss: 0.621113, ACC:0.910256\n",
      "<130>:Loss: 0.620582, ACC:0.910256\n",
      "<131>:Loss: 0.620053, ACC:0.910256\n",
      "<132>:Loss: 0.619524, ACC:0.923077\n",
      "<133>:Loss: 0.618996, ACC:0.923077\n",
      "<134>:Loss: 0.618469, ACC:0.923077\n",
      "<135>:Loss: 0.617943, ACC:0.923077\n",
      "<136>:Loss: 0.617417, ACC:0.935897\n",
      "<137>:Loss: 0.616892, ACC:0.935897\n",
      "<138>:Loss: 0.616368, ACC:0.935897\n",
      "<139>:Loss: 0.615845, ACC:0.935897\n",
      "<140>:Loss: 0.615323, ACC:0.935897\n",
      "<141>:Loss: 0.614801, ACC:0.935897\n",
      "<142>:Loss: 0.614281, ACC:0.935897\n",
      "<143>:Loss: 0.613761, ACC:0.935897\n",
      "<144>:Loss: 0.613242, ACC:0.935897\n",
      "<145>:Loss: 0.612723, ACC:0.935897\n",
      "<146>:Loss: 0.612206, ACC:0.935897\n",
      "<147>:Loss: 0.611689, ACC:0.935897\n",
      "<148>:Loss: 0.611173, ACC:0.935897\n",
      "<149>:Loss: 0.610658, ACC:0.935897\n",
      "<150>:Loss: 0.610144, ACC:0.935897\n",
      "<151>:Loss: 0.609630, ACC:0.935897\n",
      "<152>:Loss: 0.609117, ACC:0.935897\n",
      "<153>:Loss: 0.608605, ACC:0.935897\n",
      "<154>:Loss: 0.608094, ACC:0.935897\n",
      "<155>:Loss: 0.607583, ACC:0.935897\n",
      "<156>:Loss: 0.607074, ACC:0.935897\n",
      "<157>:Loss: 0.606565, ACC:0.935897\n",
      "<158>:Loss: 0.606057, ACC:0.935897\n",
      "<159>:Loss: 0.605549, ACC:0.935897\n",
      "<160>:Loss: 0.605043, ACC:0.935897\n",
      "<161>:Loss: 0.604537, ACC:0.935897\n",
      "<162>:Loss: 0.604032, ACC:0.935897\n",
      "<163>:Loss: 0.603528, ACC:0.935897\n",
      "<164>:Loss: 0.603024, ACC:0.935897\n",
      "<165>:Loss: 0.602521, ACC:0.935897\n",
      "<166>:Loss: 0.602020, ACC:0.935897\n",
      "<167>:Loss: 0.601518, ACC:0.948718\n",
      "<168>:Loss: 0.601018, ACC:0.961538\n",
      "<169>:Loss: 0.600518, ACC:0.961538\n",
      "<170>:Loss: 0.600019, ACC:0.961538\n",
      "<171>:Loss: 0.599521, ACC:0.961538\n",
      "<172>:Loss: 0.599024, ACC:0.961538\n",
      "<173>:Loss: 0.598527, ACC:0.961538\n",
      "<174>:Loss: 0.598031, ACC:0.961538\n",
      "<175>:Loss: 0.597536, ACC:0.961538\n",
      "<176>:Loss: 0.597042, ACC:0.961538\n",
      "<177>:Loss: 0.596548, ACC:0.961538\n",
      "<178>:Loss: 0.596056, ACC:0.961538\n",
      "<179>:Loss: 0.595563, ACC:0.961538\n",
      "<180>:Loss: 0.595072, ACC:0.961538\n",
      "<181>:Loss: 0.594581, ACC:0.961538\n",
      "<182>:Loss: 0.594092, ACC:0.961538\n",
      "<183>:Loss: 0.593602, ACC:0.961538\n",
      "<184>:Loss: 0.593114, ACC:0.961538\n",
      "<185>:Loss: 0.592627, ACC:0.961538\n",
      "<186>:Loss: 0.592140, ACC:0.961538\n",
      "<187>:Loss: 0.591653, ACC:0.961538\n",
      "<188>:Loss: 0.591168, ACC:0.961538\n",
      "<189>:Loss: 0.590683, ACC:0.961538\n",
      "<190>:Loss: 0.590199, ACC:0.961538\n",
      "<191>:Loss: 0.589716, ACC:0.961538\n",
      "<192>:Loss: 0.589234, ACC:0.961538\n",
      "<193>:Loss: 0.588752, ACC:0.961538\n",
      "<194>:Loss: 0.588271, ACC:0.961538\n",
      "<195>:Loss: 0.587791, ACC:0.961538\n",
      "<196>:Loss: 0.587311, ACC:0.961538\n",
      "<197>:Loss: 0.586832, ACC:0.961538\n",
      "<198>:Loss: 0.586354, ACC:0.961538\n",
      "<199>:Loss: 0.585877, ACC:0.961538\n",
      "<200>:Loss: 0.585400, ACC:0.961538\n",
      "<201>:Loss: 0.584924, ACC:0.961538\n",
      "<202>:Loss: 0.584449, ACC:0.961538\n",
      "<203>:Loss: 0.583974, ACC:0.961538\n",
      "<204>:Loss: 0.583501, ACC:0.961538\n",
      "<205>:Loss: 0.583028, ACC:0.961538\n",
      "<206>:Loss: 0.582555, ACC:0.961538\n",
      "<207>:Loss: 0.582084, ACC:0.961538\n",
      "<208>:Loss: 0.581613, ACC:0.961538\n",
      "<209>:Loss: 0.581142, ACC:0.961538\n",
      "<210>:Loss: 0.580673, ACC:0.961538\n",
      "<211>:Loss: 0.580204, ACC:0.961538\n",
      "<212>:Loss: 0.579736, ACC:0.961538\n",
      "<213>:Loss: 0.579269, ACC:0.961538\n",
      "<214>:Loss: 0.578802, ACC:0.961538\n",
      "<215>:Loss: 0.578336, ACC:0.961538\n",
      "<216>:Loss: 0.577871, ACC:0.961538\n",
      "<217>:Loss: 0.577406, ACC:0.961538\n",
      "<218>:Loss: 0.576942, ACC:0.961538\n",
      "<219>:Loss: 0.576479, ACC:0.961538\n",
      "<220>:Loss: 0.576016, ACC:0.961538\n",
      "<221>:Loss: 0.575555, ACC:0.961538\n",
      "<222>:Loss: 0.575094, ACC:0.961538\n",
      "<223>:Loss: 0.574633, ACC:0.961538\n",
      "<224>:Loss: 0.574174, ACC:0.961538\n",
      "<225>:Loss: 0.573715, ACC:0.961538\n",
      "<226>:Loss: 0.573256, ACC:0.961538\n",
      "<227>:Loss: 0.572799, ACC:0.961538\n",
      "<228>:Loss: 0.572342, ACC:0.961538\n",
      "<229>:Loss: 0.571885, ACC:0.961538\n",
      "<230>:Loss: 0.571430, ACC:0.961538\n",
      "<231>:Loss: 0.570975, ACC:0.961538\n",
      "<232>:Loss: 0.570521, ACC:0.961538\n",
      "<233>:Loss: 0.570067, ACC:0.961538\n",
      "<234>:Loss: 0.569614, ACC:0.961538\n",
      "<235>:Loss: 0.569162, ACC:0.961538\n",
      "<236>:Loss: 0.568711, ACC:0.961538\n",
      "<237>:Loss: 0.568260, ACC:0.961538\n",
      "<238>:Loss: 0.567810, ACC:0.961538\n",
      "<239>:Loss: 0.567360, ACC:0.961538\n",
      "<240>:Loss: 0.566911, ACC:0.961538\n",
      "<241>:Loss: 0.566463, ACC:0.961538\n",
      "<242>:Loss: 0.566016, ACC:0.961538\n",
      "<243>:Loss: 0.565569, ACC:0.961538\n",
      "<244>:Loss: 0.565123, ACC:0.961538\n",
      "<245>:Loss: 0.564677, ACC:0.961538\n",
      "<246>:Loss: 0.564233, ACC:0.961538\n",
      "<247>:Loss: 0.563789, ACC:0.961538\n",
      "<248>:Loss: 0.563345, ACC:0.961538\n",
      "<249>:Loss: 0.562902, ACC:0.961538\n",
      "<250>:Loss: 0.562460, ACC:0.961538\n",
      "<251>:Loss: 0.562019, ACC:0.961538\n",
      "<252>:Loss: 0.561578, ACC:0.961538\n",
      "<253>:Loss: 0.561138, ACC:0.961538\n",
      "<254>:Loss: 0.560698, ACC:0.961538\n",
      "<255>:Loss: 0.560259, ACC:0.961538\n",
      "<256>:Loss: 0.559821, ACC:0.961538\n",
      "<257>:Loss: 0.559384, ACC:0.961538\n",
      "<258>:Loss: 0.558947, ACC:0.961538\n",
      "<259>:Loss: 0.558510, ACC:0.961538\n",
      "<260>:Loss: 0.558075, ACC:0.961538\n",
      "<261>:Loss: 0.557640, ACC:0.961538\n",
      "<262>:Loss: 0.557206, ACC:0.961538\n",
      "<263>:Loss: 0.556772, ACC:0.961538\n",
      "<264>:Loss: 0.556339, ACC:0.961538\n",
      "<265>:Loss: 0.555907, ACC:0.961538\n",
      "<266>:Loss: 0.555475, ACC:0.961538\n",
      "<267>:Loss: 0.555044, ACC:0.961538\n",
      "<268>:Loss: 0.554613, ACC:0.961538\n",
      "<269>:Loss: 0.554184, ACC:0.961538\n",
      "<270>:Loss: 0.553754, ACC:0.961538\n",
      "<271>:Loss: 0.553326, ACC:0.961538\n",
      "<272>:Loss: 0.552898, ACC:0.961538\n",
      "<273>:Loss: 0.552471, ACC:0.961538\n",
      "<274>:Loss: 0.552044, ACC:0.961538\n",
      "<275>:Loss: 0.551618, ACC:0.961538\n",
      "<276>:Loss: 0.551193, ACC:0.961538\n",
      "<277>:Loss: 0.550768, ACC:0.961538\n",
      "<278>:Loss: 0.550344, ACC:0.961538\n",
      "<279>:Loss: 0.549921, ACC:0.961538\n",
      "<280>:Loss: 0.549498, ACC:0.961538\n",
      "<281>:Loss: 0.549075, ACC:0.961538\n",
      "<282>:Loss: 0.548654, ACC:0.961538\n",
      "<283>:Loss: 0.548233, ACC:0.961538\n",
      "<284>:Loss: 0.547813, ACC:0.961538\n",
      "<285>:Loss: 0.547393, ACC:0.961538\n",
      "<286>:Loss: 0.546974, ACC:0.961538\n",
      "<287>:Loss: 0.546555, ACC:0.961538\n",
      "<288>:Loss: 0.546137, ACC:0.961538\n",
      "<289>:Loss: 0.545720, ACC:0.961538\n",
      "<290>:Loss: 0.545303, ACC:0.961538\n",
      "<291>:Loss: 0.544887, ACC:0.974359\n",
      "<292>:Loss: 0.544472, ACC:0.974359\n",
      "<293>:Loss: 0.544057, ACC:0.974359\n",
      "<294>:Loss: 0.543643, ACC:0.974359\n",
      "<295>:Loss: 0.543229, ACC:0.974359\n",
      "<296>:Loss: 0.542816, ACC:0.974359\n",
      "<297>:Loss: 0.542404, ACC:0.974359\n",
      "<298>:Loss: 0.541992, ACC:0.974359\n",
      "<299>:Loss: 0.541581, ACC:0.974359\n",
      "<300>:Loss: 0.541171, ACC:0.974359\n",
      "<301>:Loss: 0.540761, ACC:0.974359\n",
      "<302>:Loss: 0.540351, ACC:0.974359\n",
      "<303>:Loss: 0.539942, ACC:0.974359\n",
      "<304>:Loss: 0.539534, ACC:0.974359\n",
      "<305>:Loss: 0.539127, ACC:0.974359\n",
      "<306>:Loss: 0.538720, ACC:0.974359\n",
      "<307>:Loss: 0.538314, ACC:0.974359\n",
      "<308>:Loss: 0.537908, ACC:0.974359\n",
      "<309>:Loss: 0.537503, ACC:0.974359\n",
      "<310>:Loss: 0.537098, ACC:0.974359\n",
      "<311>:Loss: 0.536694, ACC:0.974359\n",
      "<312>:Loss: 0.536291, ACC:0.974359\n",
      "<313>:Loss: 0.535888, ACC:0.974359\n",
      "<314>:Loss: 0.535486, ACC:0.974359\n",
      "<315>:Loss: 0.535084, ACC:0.974359\n",
      "<316>:Loss: 0.534683, ACC:0.974359\n",
      "<317>:Loss: 0.534282, ACC:0.974359\n",
      "<318>:Loss: 0.533883, ACC:0.974359\n",
      "<319>:Loss: 0.533483, ACC:0.974359\n",
      "<320>:Loss: 0.533085, ACC:0.974359\n",
      "<321>:Loss: 0.532686, ACC:0.974359\n",
      "<322>:Loss: 0.532289, ACC:0.974359\n",
      "<323>:Loss: 0.531892, ACC:0.974359\n",
      "<324>:Loss: 0.531496, ACC:0.974359\n",
      "<325>:Loss: 0.531100, ACC:0.974359\n",
      "<326>:Loss: 0.530705, ACC:0.974359\n",
      "<327>:Loss: 0.530310, ACC:0.974359\n",
      "<328>:Loss: 0.529916, ACC:0.974359\n",
      "<329>:Loss: 0.529522, ACC:0.974359\n",
      "<330>:Loss: 0.529129, ACC:0.974359\n",
      "<331>:Loss: 0.528737, ACC:0.974359\n",
      "<332>:Loss: 0.528345, ACC:0.974359\n",
      "<333>:Loss: 0.527954, ACC:0.974359\n",
      "<334>:Loss: 0.527564, ACC:0.974359\n",
      "<335>:Loss: 0.527173, ACC:0.974359\n",
      "<336>:Loss: 0.526784, ACC:0.974359\n",
      "<337>:Loss: 0.526395, ACC:0.974359\n",
      "<338>:Loss: 0.526007, ACC:0.974359\n",
      "<339>:Loss: 0.525619, ACC:0.974359\n",
      "<340>:Loss: 0.525231, ACC:0.974359\n",
      "<341>:Loss: 0.524845, ACC:0.974359\n",
      "<342>:Loss: 0.524459, ACC:0.974359\n",
      "<343>:Loss: 0.524073, ACC:0.974359\n",
      "<344>:Loss: 0.523688, ACC:0.974359\n",
      "<345>:Loss: 0.523304, ACC:0.974359\n",
      "<346>:Loss: 0.522920, ACC:0.974359\n",
      "<347>:Loss: 0.522536, ACC:0.974359\n",
      "<348>:Loss: 0.522153, ACC:0.974359\n",
      "<349>:Loss: 0.521771, ACC:0.974359\n",
      "<350>:Loss: 0.521389, ACC:0.974359\n",
      "<351>:Loss: 0.521008, ACC:0.974359\n",
      "<352>:Loss: 0.520628, ACC:0.974359\n",
      "<353>:Loss: 0.520248, ACC:0.974359\n",
      "<354>:Loss: 0.519868, ACC:0.974359\n",
      "<355>:Loss: 0.519489, ACC:0.974359\n",
      "<356>:Loss: 0.519111, ACC:0.974359\n",
      "<357>:Loss: 0.518733, ACC:0.974359\n",
      "<358>:Loss: 0.518356, ACC:0.974359\n",
      "<359>:Loss: 0.517979, ACC:0.974359\n",
      "<360>:Loss: 0.517603, ACC:0.974359\n",
      "<361>:Loss: 0.517227, ACC:0.974359\n",
      "<362>:Loss: 0.516852, ACC:0.974359\n",
      "<363>:Loss: 0.516477, ACC:0.974359\n",
      "<364>:Loss: 0.516103, ACC:0.974359\n",
      "<365>:Loss: 0.515730, ACC:0.974359\n",
      "<366>:Loss: 0.515357, ACC:0.974359\n",
      "<367>:Loss: 0.514984, ACC:0.974359\n",
      "<368>:Loss: 0.514612, ACC:0.974359\n",
      "<369>:Loss: 0.514241, ACC:0.974359\n",
      "<370>:Loss: 0.513870, ACC:0.974359\n",
      "<371>:Loss: 0.513500, ACC:0.974359\n",
      "<372>:Loss: 0.513130, ACC:0.974359\n",
      "<373>:Loss: 0.512761, ACC:0.974359\n",
      "<374>:Loss: 0.512392, ACC:0.974359\n",
      "<375>:Loss: 0.512024, ACC:0.974359\n",
      "<376>:Loss: 0.511656, ACC:0.974359\n",
      "<377>:Loss: 0.511289, ACC:0.974359\n",
      "<378>:Loss: 0.510922, ACC:0.974359\n",
      "<379>:Loss: 0.510556, ACC:0.974359\n",
      "<380>:Loss: 0.510190, ACC:0.974359\n",
      "<381>:Loss: 0.509825, ACC:0.974359\n",
      "<382>:Loss: 0.509461, ACC:0.974359\n",
      "<383>:Loss: 0.509097, ACC:0.974359\n",
      "<384>:Loss: 0.508733, ACC:0.974359\n",
      "<385>:Loss: 0.508370, ACC:0.974359\n",
      "<386>:Loss: 0.508008, ACC:0.974359\n",
      "<387>:Loss: 0.507646, ACC:0.974359\n",
      "<388>:Loss: 0.507284, ACC:0.974359\n",
      "<389>:Loss: 0.506923, ACC:0.974359\n",
      "<390>:Loss: 0.506563, ACC:0.974359\n",
      "<391>:Loss: 0.506203, ACC:0.974359\n",
      "<392>:Loss: 0.505843, ACC:0.974359\n",
      "<393>:Loss: 0.505485, ACC:0.974359\n",
      "<394>:Loss: 0.505126, ACC:0.974359\n",
      "<395>:Loss: 0.504768, ACC:0.974359\n",
      "<396>:Loss: 0.504411, ACC:0.974359\n",
      "<397>:Loss: 0.504054, ACC:0.974359\n",
      "<398>:Loss: 0.503698, ACC:0.974359\n",
      "<399>:Loss: 0.503342, ACC:0.974359\n",
      "<400>:Loss: 0.502987, ACC:0.974359\n",
      "<401>:Loss: 0.502632, ACC:0.974359\n",
      "<402>:Loss: 0.502278, ACC:0.974359\n",
      "<403>:Loss: 0.501924, ACC:0.974359\n",
      "<404>:Loss: 0.501570, ACC:0.974359\n",
      "<405>:Loss: 0.501217, ACC:0.974359\n",
      "<406>:Loss: 0.500865, ACC:0.974359\n",
      "<407>:Loss: 0.500513, ACC:0.974359\n",
      "<408>:Loss: 0.500162, ACC:0.974359\n",
      "<409>:Loss: 0.499811, ACC:0.974359\n",
      "<410>:Loss: 0.499461, ACC:0.974359\n",
      "<411>:Loss: 0.499111, ACC:0.974359\n",
      "<412>:Loss: 0.498762, ACC:0.974359\n",
      "<413>:Loss: 0.498413, ACC:0.974359\n",
      "<414>:Loss: 0.498064, ACC:0.974359\n",
      "<415>:Loss: 0.497716, ACC:0.974359\n",
      "<416>:Loss: 0.497369, ACC:0.974359\n",
      "<417>:Loss: 0.497022, ACC:0.974359\n",
      "<418>:Loss: 0.496676, ACC:0.974359\n",
      "<419>:Loss: 0.496330, ACC:0.974359\n",
      "<420>:Loss: 0.495984, ACC:0.974359\n",
      "<421>:Loss: 0.495639, ACC:0.974359\n",
      "<422>:Loss: 0.495295, ACC:0.974359\n",
      "<423>:Loss: 0.494951, ACC:0.974359\n",
      "<424>:Loss: 0.494607, ACC:0.974359\n",
      "<425>:Loss: 0.494264, ACC:0.974359\n",
      "<426>:Loss: 0.493922, ACC:0.974359\n",
      "<427>:Loss: 0.493580, ACC:0.974359\n",
      "<428>:Loss: 0.493238, ACC:0.974359\n",
      "<429>:Loss: 0.492897, ACC:0.974359\n",
      "<430>:Loss: 0.492557, ACC:0.974359\n",
      "<431>:Loss: 0.492216, ACC:0.974359\n",
      "<432>:Loss: 0.491877, ACC:0.974359\n",
      "<433>:Loss: 0.491537, ACC:0.974359\n",
      "<434>:Loss: 0.491199, ACC:0.974359\n",
      "<435>:Loss: 0.490860, ACC:0.974359\n",
      "<436>:Loss: 0.490523, ACC:0.974359\n",
      "<437>:Loss: 0.490185, ACC:0.974359\n",
      "<438>:Loss: 0.489849, ACC:0.974359\n",
      "<439>:Loss: 0.489512, ACC:0.974359\n",
      "<440>:Loss: 0.489176, ACC:0.974359\n",
      "<441>:Loss: 0.488841, ACC:0.974359\n",
      "<442>:Loss: 0.488506, ACC:0.974359\n",
      "<443>:Loss: 0.488171, ACC:0.974359\n",
      "<444>:Loss: 0.487837, ACC:0.974359\n",
      "<445>:Loss: 0.487504, ACC:0.974359\n",
      "<446>:Loss: 0.487171, ACC:0.974359\n",
      "<447>:Loss: 0.486838, ACC:0.974359\n",
      "<448>:Loss: 0.486506, ACC:0.974359\n",
      "<449>:Loss: 0.486174, ACC:0.974359\n",
      "<450>:Loss: 0.485843, ACC:0.974359\n",
      "<451>:Loss: 0.485512, ACC:0.974359\n",
      "<452>:Loss: 0.485182, ACC:0.974359\n",
      "<453>:Loss: 0.484852, ACC:0.974359\n",
      "<454>:Loss: 0.484522, ACC:0.974359\n",
      "<455>:Loss: 0.484194, ACC:0.974359\n",
      "<456>:Loss: 0.483865, ACC:0.974359\n",
      "<457>:Loss: 0.483537, ACC:0.974359\n",
      "<458>:Loss: 0.483209, ACC:0.974359\n",
      "<459>:Loss: 0.482882, ACC:0.974359\n",
      "<460>:Loss: 0.482555, ACC:0.974359\n",
      "<461>:Loss: 0.482229, ACC:0.974359\n",
      "<462>:Loss: 0.481903, ACC:0.974359\n",
      "<463>:Loss: 0.481578, ACC:0.974359\n",
      "<464>:Loss: 0.481253, ACC:0.974359\n",
      "<465>:Loss: 0.480929, ACC:0.974359\n",
      "<466>:Loss: 0.480605, ACC:0.974359\n",
      "<467>:Loss: 0.480281, ACC:0.974359\n",
      "<468>:Loss: 0.479958, ACC:0.974359\n",
      "<469>:Loss: 0.479636, ACC:0.974359\n",
      "<470>:Loss: 0.479313, ACC:0.974359\n",
      "<471>:Loss: 0.478991, ACC:0.974359\n",
      "<472>:Loss: 0.478670, ACC:0.974359\n",
      "<473>:Loss: 0.478349, ACC:0.974359\n",
      "<474>:Loss: 0.478029, ACC:0.974359\n",
      "<475>:Loss: 0.477709, ACC:0.974359\n",
      "<476>:Loss: 0.477389, ACC:0.974359\n",
      "<477>:Loss: 0.477070, ACC:0.974359\n",
      "<478>:Loss: 0.476751, ACC:0.974359\n",
      "<479>:Loss: 0.476433, ACC:0.974359\n",
      "<480>:Loss: 0.476115, ACC:0.974359\n",
      "<481>:Loss: 0.475798, ACC:0.974359\n",
      "<482>:Loss: 0.475481, ACC:0.974359\n",
      "<483>:Loss: 0.475165, ACC:0.974359\n",
      "<484>:Loss: 0.474848, ACC:0.974359\n",
      "<485>:Loss: 0.474533, ACC:0.974359\n",
      "<486>:Loss: 0.474218, ACC:0.974359\n",
      "<487>:Loss: 0.473903, ACC:0.974359\n",
      "<488>:Loss: 0.473588, ACC:0.974359\n",
      "<489>:Loss: 0.473275, ACC:0.974359\n",
      "<490>:Loss: 0.472961, ACC:0.974359\n",
      "<491>:Loss: 0.472648, ACC:0.974359\n",
      "<492>:Loss: 0.472335, ACC:0.974359\n",
      "<493>:Loss: 0.472023, ACC:0.974359\n",
      "<494>:Loss: 0.471711, ACC:0.974359\n",
      "<495>:Loss: 0.471400, ACC:0.974359\n",
      "<496>:Loss: 0.471089, ACC:0.974359\n",
      "<497>:Loss: 0.470779, ACC:0.974359\n",
      "<498>:Loss: 0.470468, ACC:0.974359\n",
      "<499>:Loss: 0.470159, ACC:0.974359\n",
      "<500>:Loss: 0.469850, ACC:0.974359\n",
      "<501>:Loss: 0.469541, ACC:0.974359\n",
      "<502>:Loss: 0.469232, ACC:0.974359\n",
      "<503>:Loss: 0.468924, ACC:0.974359\n",
      "<504>:Loss: 0.468617, ACC:0.974359\n",
      "<505>:Loss: 0.468310, ACC:0.974359\n",
      "<506>:Loss: 0.468003, ACC:0.974359\n",
      "<507>:Loss: 0.467697, ACC:0.974359\n",
      "<508>:Loss: 0.467391, ACC:0.974359\n",
      "<509>:Loss: 0.467085, ACC:0.974359\n",
      "<510>:Loss: 0.466780, ACC:0.974359\n",
      "<511>:Loss: 0.466475, ACC:0.974359\n",
      "<512>:Loss: 0.466171, ACC:0.974359\n",
      "<513>:Loss: 0.465867, ACC:0.974359\n",
      "<514>:Loss: 0.465564, ACC:0.974359\n",
      "<515>:Loss: 0.465261, ACC:0.974359\n",
      "<516>:Loss: 0.464958, ACC:0.974359\n",
      "<517>:Loss: 0.464656, ACC:0.974359\n",
      "<518>:Loss: 0.464354, ACC:0.974359\n",
      "<519>:Loss: 0.464053, ACC:0.974359\n",
      "<520>:Loss: 0.463752, ACC:0.974359\n",
      "<521>:Loss: 0.463451, ACC:0.974359\n",
      "<522>:Loss: 0.463151, ACC:0.974359\n",
      "<523>:Loss: 0.462851, ACC:0.974359\n",
      "<524>:Loss: 0.462552, ACC:0.974359\n",
      "<525>:Loss: 0.462253, ACC:0.974359\n",
      "<526>:Loss: 0.461955, ACC:0.974359\n",
      "<527>:Loss: 0.461656, ACC:0.974359\n",
      "<528>:Loss: 0.461359, ACC:0.974359\n",
      "<529>:Loss: 0.461061, ACC:0.974359\n",
      "<530>:Loss: 0.460764, ACC:0.974359\n",
      "<531>:Loss: 0.460468, ACC:0.974359\n",
      "<532>:Loss: 0.460172, ACC:0.974359\n",
      "<533>:Loss: 0.459876, ACC:0.974359\n",
      "<534>:Loss: 0.459580, ACC:0.974359\n",
      "<535>:Loss: 0.459285, ACC:0.974359\n",
      "<536>:Loss: 0.458991, ACC:0.974359\n",
      "<537>:Loss: 0.458697, ACC:0.974359\n",
      "<538>:Loss: 0.458403, ACC:0.974359\n",
      "<539>:Loss: 0.458110, ACC:0.974359\n",
      "<540>:Loss: 0.457817, ACC:0.974359\n",
      "<541>:Loss: 0.457524, ACC:0.974359\n",
      "<542>:Loss: 0.457232, ACC:0.974359\n",
      "<543>:Loss: 0.456940, ACC:0.974359\n",
      "<544>:Loss: 0.456648, ACC:0.974359\n",
      "<545>:Loss: 0.456357, ACC:0.974359\n",
      "<546>:Loss: 0.456067, ACC:0.974359\n",
      "<547>:Loss: 0.455776, ACC:0.974359\n",
      "<548>:Loss: 0.455487, ACC:0.974359\n",
      "<549>:Loss: 0.455197, ACC:0.974359\n",
      "<550>:Loss: 0.454908, ACC:0.974359\n",
      "<551>:Loss: 0.454619, ACC:0.974359\n",
      "<552>:Loss: 0.454331, ACC:0.974359\n",
      "<553>:Loss: 0.454043, ACC:0.974359\n",
      "<554>:Loss: 0.453755, ACC:0.974359\n",
      "<555>:Loss: 0.453468, ACC:0.974359\n",
      "<556>:Loss: 0.453181, ACC:0.974359\n",
      "<557>:Loss: 0.452895, ACC:0.974359\n",
      "<558>:Loss: 0.452609, ACC:0.974359\n",
      "<559>:Loss: 0.452323, ACC:0.974359\n",
      "<560>:Loss: 0.452038, ACC:0.974359\n",
      "<561>:Loss: 0.451753, ACC:0.974359\n",
      "<562>:Loss: 0.451468, ACC:0.974359\n",
      "<563>:Loss: 0.451184, ACC:0.974359\n",
      "<564>:Loss: 0.450900, ACC:0.974359\n",
      "<565>:Loss: 0.450617, ACC:0.974359\n",
      "<566>:Loss: 0.450334, ACC:0.974359\n",
      "<567>:Loss: 0.450051, ACC:0.974359\n",
      "<568>:Loss: 0.449769, ACC:0.974359\n",
      "<569>:Loss: 0.449487, ACC:0.974359\n",
      "<570>:Loss: 0.449205, ACC:0.974359\n",
      "<571>:Loss: 0.448924, ACC:0.974359\n",
      "<572>:Loss: 0.448643, ACC:0.974359\n",
      "<573>:Loss: 0.448363, ACC:0.974359\n",
      "<574>:Loss: 0.448083, ACC:0.974359\n",
      "<575>:Loss: 0.447803, ACC:0.974359\n",
      "<576>:Loss: 0.447524, ACC:0.974359\n",
      "<577>:Loss: 0.447245, ACC:0.974359\n",
      "<578>:Loss: 0.446966, ACC:0.974359\n",
      "<579>:Loss: 0.446688, ACC:0.974359\n",
      "<580>:Loss: 0.446410, ACC:0.974359\n",
      "<581>:Loss: 0.446133, ACC:0.974359\n",
      "<582>:Loss: 0.445855, ACC:0.974359\n",
      "<583>:Loss: 0.445579, ACC:0.974359\n",
      "<584>:Loss: 0.445302, ACC:0.974359\n",
      "<585>:Loss: 0.445026, ACC:0.974359\n",
      "<586>:Loss: 0.444750, ACC:0.974359\n",
      "<587>:Loss: 0.444475, ACC:0.974359\n",
      "<588>:Loss: 0.444200, ACC:0.974359\n",
      "<589>:Loss: 0.443926, ACC:0.974359\n",
      "<590>:Loss: 0.443651, ACC:0.974359\n",
      "<591>:Loss: 0.443377, ACC:0.974359\n",
      "<592>:Loss: 0.443104, ACC:0.974359\n",
      "<593>:Loss: 0.442831, ACC:0.974359\n",
      "<594>:Loss: 0.442558, ACC:0.974359\n",
      "<595>:Loss: 0.442285, ACC:0.974359\n",
      "<596>:Loss: 0.442013, ACC:0.974359\n",
      "<597>:Loss: 0.441741, ACC:0.974359\n",
      "<598>:Loss: 0.441470, ACC:0.974359\n",
      "<599>:Loss: 0.441199, ACC:0.974359\n",
      "<600>:Loss: 0.440928, ACC:0.974359\n",
      "<601>:Loss: 0.440658, ACC:0.974359\n",
      "<602>:Loss: 0.440388, ACC:0.974359\n",
      "<603>:Loss: 0.440118, ACC:0.974359\n",
      "<604>:Loss: 0.439849, ACC:0.974359\n",
      "<605>:Loss: 0.439580, ACC:0.974359\n",
      "<606>:Loss: 0.439312, ACC:0.974359\n",
      "<607>:Loss: 0.439043, ACC:0.974359\n",
      "<608>:Loss: 0.438775, ACC:0.974359\n",
      "<609>:Loss: 0.438508, ACC:0.974359\n",
      "<610>:Loss: 0.438241, ACC:0.974359\n",
      "<611>:Loss: 0.437974, ACC:0.974359\n",
      "<612>:Loss: 0.437707, ACC:0.974359\n",
      "<613>:Loss: 0.437441, ACC:0.974359\n",
      "<614>:Loss: 0.437175, ACC:0.974359\n",
      "<615>:Loss: 0.436910, ACC:0.974359\n",
      "<616>:Loss: 0.436644, ACC:0.974359\n",
      "<617>:Loss: 0.436380, ACC:0.974359\n",
      "<618>:Loss: 0.436115, ACC:0.974359\n",
      "<619>:Loss: 0.435851, ACC:0.974359\n",
      "<620>:Loss: 0.435587, ACC:0.974359\n",
      "<621>:Loss: 0.435324, ACC:0.974359\n",
      "<622>:Loss: 0.435061, ACC:0.974359\n",
      "<623>:Loss: 0.434798, ACC:0.974359\n",
      "<624>:Loss: 0.434536, ACC:0.974359\n",
      "<625>:Loss: 0.434274, ACC:0.974359\n",
      "<626>:Loss: 0.434012, ACC:0.974359\n",
      "<627>:Loss: 0.433750, ACC:0.974359\n",
      "<628>:Loss: 0.433489, ACC:0.974359\n",
      "<629>:Loss: 0.433229, ACC:0.974359\n",
      "<630>:Loss: 0.432968, ACC:0.974359\n",
      "<631>:Loss: 0.432708, ACC:0.974359\n",
      "<632>:Loss: 0.432448, ACC:0.974359\n",
      "<633>:Loss: 0.432189, ACC:0.974359\n",
      "<634>:Loss: 0.431930, ACC:0.974359\n",
      "<635>:Loss: 0.431671, ACC:0.974359\n",
      "<636>:Loss: 0.431413, ACC:0.974359\n",
      "<637>:Loss: 0.431155, ACC:0.974359\n",
      "<638>:Loss: 0.430897, ACC:0.974359\n",
      "<639>:Loss: 0.430640, ACC:0.974359\n",
      "<640>:Loss: 0.430383, ACC:0.974359\n",
      "<641>:Loss: 0.430126, ACC:0.974359\n",
      "<642>:Loss: 0.429869, ACC:0.974359\n",
      "<643>:Loss: 0.429613, ACC:0.974359\n",
      "<644>:Loss: 0.429357, ACC:0.974359\n",
      "<645>:Loss: 0.429102, ACC:0.974359\n",
      "<646>:Loss: 0.428847, ACC:0.974359\n",
      "<647>:Loss: 0.428592, ACC:0.974359\n",
      "<648>:Loss: 0.428338, ACC:0.974359\n",
      "<649>:Loss: 0.428083, ACC:0.974359\n",
      "<650>:Loss: 0.427830, ACC:0.974359\n",
      "<651>:Loss: 0.427576, ACC:0.974359\n",
      "<652>:Loss: 0.427323, ACC:0.974359\n",
      "<653>:Loss: 0.427070, ACC:0.974359\n",
      "<654>:Loss: 0.426818, ACC:0.974359\n",
      "<655>:Loss: 0.426565, ACC:0.974359\n",
      "<656>:Loss: 0.426313, ACC:0.974359\n",
      "<657>:Loss: 0.426062, ACC:0.974359\n",
      "<658>:Loss: 0.425811, ACC:0.974359\n",
      "<659>:Loss: 0.425560, ACC:0.974359\n",
      "<660>:Loss: 0.425309, ACC:0.974359\n",
      "<661>:Loss: 0.425059, ACC:0.974359\n",
      "<662>:Loss: 0.424809, ACC:0.974359\n",
      "<663>:Loss: 0.424559, ACC:0.974359\n",
      "<664>:Loss: 0.424310, ACC:0.974359\n",
      "<665>:Loss: 0.424061, ACC:0.974359\n",
      "<666>:Loss: 0.423812, ACC:0.974359\n",
      "<667>:Loss: 0.423564, ACC:0.974359\n",
      "<668>:Loss: 0.423315, ACC:0.974359\n",
      "<669>:Loss: 0.423068, ACC:0.974359\n",
      "<670>:Loss: 0.422820, ACC:0.974359\n",
      "<671>:Loss: 0.422573, ACC:0.974359\n",
      "<672>:Loss: 0.422326, ACC:0.974359\n",
      "<673>:Loss: 0.422080, ACC:0.974359\n",
      "<674>:Loss: 0.421833, ACC:0.974359\n",
      "<675>:Loss: 0.421587, ACC:0.974359\n",
      "<676>:Loss: 0.421342, ACC:0.974359\n",
      "<677>:Loss: 0.421097, ACC:0.974359\n",
      "<678>:Loss: 0.420852, ACC:0.974359\n",
      "<679>:Loss: 0.420607, ACC:0.974359\n",
      "<680>:Loss: 0.420363, ACC:0.974359\n",
      "<681>:Loss: 0.420118, ACC:0.974359\n",
      "<682>:Loss: 0.419875, ACC:0.974359\n",
      "<683>:Loss: 0.419631, ACC:0.974359\n",
      "<684>:Loss: 0.419388, ACC:0.974359\n",
      "<685>:Loss: 0.419145, ACC:0.974359\n",
      "<686>:Loss: 0.418903, ACC:0.974359\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(5,5))\r\n",
    "plt.plot(ce,color=\"red\",label=\"LOSS\")\r\n",
    "plt.plot(acc,color=\"blue\",label=\"ACC\")\r\n",
    "plt.legend\r\n",
    "plt.text(1,2,\"W:%s\" %W)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.xlim(train_x[:,0].min(axis=0),train_x[:,0].max(axis=0))\r\n",
    "plt.ylim(train_x[:,1].min(axis=0),train_x[:,1].max(axis=0))\r\n",
    "X,Y=np.meshgrid(train_x[:,0],train_x[:,1])\r\n",
    "Z=X+Y\r\n",
    "plt.pcolormesh(X,Y,Z,cmap=\"rainbow\")\r\n",
    "plt.scatter(train_x[:,0],train_x[:,1], c=train_y, cmap='brg' )\r\n",
    "x_=[5.8,3.25]\r\n",
    "yhats=-(W[0]+W[1]*x_)/W[2]\r\n",
    "plt.plot(x_,yhats,color='red')\r\n",
    "\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "boston_housing=tf.keras.datasets.boston_housing\r\n",
    "(train_x, train_y),(test_x, test_y) = boston_housing.load_data()\r\n",
    "#print(np.shape(train_x))\r\n",
    "plt.scatter(train_x[:,5], train_y)\r\n",
    "\r\n",
    "print(train_x.shape)\r\n",
    "\r\n",
    "x=train_x[:,5]\r\n",
    "y=train_y\r\n",
    "\r\n",
    "meanX=tf.reduce_mean(x)\r\n",
    "meanY=tf.reduce_mean(y)\r\n",
    "\r\n",
    "sumXY=tf.reduce_sum( (x-meanX)*(y-meanY) )\r\n",
    "sumX=tf.reduce_sum( (x-meanX)*(y-meanX) )\r\n",
    "\r\n",
    "w=sumXY/sumX\r\n",
    "b=meanY-w*meanX\r\n",
    "print(\"w:%d, b:%d\" %(w,b))\r\n",
    "hy=x*w+b\r\n",
    "plt.plot(x,hy,\"red\")\r\n",
    "#plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "XX=np.insert(train_x[:,4:6], 2, 1, axis=1)\r\n",
    "YY=y.T.reshape(-1,1)\r\n",
    "print(XX)\r\n",
    "print(np.shape(XX))\r\n",
    "print(np.shape(YY))\r\n",
    "\r\n",
    "AA=np.matmul(XX.T, XX)\r\n",
    "AAI=np.linalg.inv(AA)\r\n",
    "\r\n",
    "BB=np.matmul(XX.T, YY)\r\n",
    "W=np.matmul(AAI,BB)\r\n",
    "\r\n",
    "#WW=np.matmul(np.linalg.inv(np.matmul(XX.T, XX)),XX.T*YY)\r\n",
    "print(\"size:%d value=%s\" %(np.size(W) , W.reshape(-1)))\r\n",
    "\r\n",
    "def f(x,y):\r\n",
    "    return (W[0]*x+W[1]*y + W[2])\r\n",
    "\r\n",
    "X,Y=np.meshgrid(train_x[:,4],train_x[:,5])\r\n",
    "Z=f(X,Y)\r\n",
    "fig = plt.figure(figsize=(8,8))\r\n",
    "ax = plt.axes(projection='3d')\r\n",
    "ax.scatter(X,Y,Z,color='r',marker='*')\r\n",
    "ax.plot_surface(X, Y, Z, cmap=\"coolwarm\")\r\n",
    "ax.view_init()\r\n",
    "#plt.show()\r\n",
    "\"\"\"\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a=tf.constant([[1,2],[3,4]])\r\n",
    "c=tf.constant([[1,2],[3,4]])\r\n",
    "#a.numpy()\r\n",
    "#b=tf.truncated_normal((100,1),2)\r\n",
    "#b=np.ceil(b.numpy())\r\n",
    "#plt.hist(b)\r\n",
    "#plt.show()\r\n",
    "\r\n",
    "print(a+c)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x=np.array([1.,2.,3.,4.])\r\n",
    "w=tf.Variable(1.)\r\n",
    "b=tf.Variable(1.)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "1/(1+tf.exp(-(w*x+b)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cach_dir=\"C:/Users/mic/.keras/datasets\"\r\n",
    "train_url=\"http://download.tensorflow.org/data/iris_training.csv\"\r\n",
    "train_path=tf.keras.utils.get_file(train_url.split('/')[-1], train_url, cach_dir)\r\n",
    "\r\n",
    "iris=pd.read_csv(train_path)\r\n",
    "irisNp = np.array(iris)\r\n",
    "\r\n",
    "train_x=irisNp[:,0:4]\r\n",
    "train_y=irisNp[:,4]\r\n",
    "\r\n",
    "\r\n",
    "train_x=train_x-np.mean(train_x,axis=0)\r\n",
    "train_x.shape, train_y.shape,train_x,train_y\r\n",
    "\r\n",
    "train_x.dtype,train_y.dtype\r\n",
    "\r\n",
    "X=tf.cast(train_x,tf.float32)\r\n",
    "Y=tf.cast(tf.one_hot(tf.constant(train_y, dtype=tf.int32), 3 ), dtype=tf.int64)\r\n",
    "X,Y,X.shape,Y.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha=0.5\r\n",
    "itr=50\r\n",
    "\r\n",
    "W1=tf.Variable(np.random.randn(4,8),dtype=np.float32)\r\n",
    "B1=tf.Variable(tf.zeros([8]), dtype=tf.float32)\r\n",
    "\r\n",
    "W2=tf.Variable(np.random.randn(8,3),dtype=np.float32)\r\n",
    "B2=tf.Variable(tf.zeros([3]), dtype=tf.float32)\r\n",
    "\r\n",
    "acc=[]\r\n",
    "cce=[]\r\n",
    "\r\n",
    "for i in range(itr+1):\r\n",
    "    with tf.GradientTape() as tape:\r\n",
    "        hidden=tf.nn.relu(tf.matmul(X,W1)+B1)\r\n",
    "        PRED=tf.nn.softmax(tf.matmul(hidden,W2)+B2)\r\n",
    "        print(PRED.shape)\r\n",
    "        LOSS=tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true=Y, y_pred=PRED))\r\n",
    "\r\n",
    "    #print(tf.argmax(PRED.numpy(),axis=1))\r\n",
    "    #print(Y)\r\n",
    "    #print(tf.argmax(Y, axis=1))\r\n",
    "    #print(  tf.cast ( tf.equal(tf.argmax(PRED.numpy(),axis=1), tf.argmax(Y, axis=1) ) , tf.float32) )\r\n",
    "    \r\n",
    "    a=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(PRED.numpy(),axis=1), train_y), tf.float32))  \r\n",
    "\r\n",
    "    #print(tf.argmax(PRED.numpy(),axis=1))\r\n",
    "    #print(train_y)\r\n",
    "\r\n",
    "    print(a)\r\n",
    "    acc.append(a)\r\n",
    "    cce.append(LOSS)\r\n",
    "\r\n",
    "    grads=tape.gradient(LOSS, [W1,B1,W2,B2])\r\n",
    "    W1.assign_sub(alpha*grads[0])\r\n",
    "    B1.assign_sub(alpha*grads[1])\r\n",
    "    W2.assign_sub(alpha*grads[2])\r\n",
    "    B2.assign_sub(alpha*grads[3])\r\n",
    "\r\n",
    "    print(\"<%d>:Loss: %f, ACC:%f\" %(i,LOSS,a))\r\n",
    "\r\n",
    "plt.text(2,2,\"Loss: %f, ACC:%f W1:%s B1:%s W2:%s B2:%s\" %(LOSS,a,W1, B1, W2, B2))\r\n",
    "plt.plot(cce,color='red')\r\n",
    "plt.plot(acc,color='blue')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('tensorflow': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "interpreter": {
   "hash": "fb4899e21819f12792cc43afe8e0116933b76af9efe7c0093f502fb73958fc94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}